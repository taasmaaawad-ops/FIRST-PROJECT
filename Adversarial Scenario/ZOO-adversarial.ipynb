{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e559b121-7a25-4c95-ada7-68161fe26313",
      "metadata": {
        "id": "e559b121-7a25-4c95-ada7-68161fe26313"
      },
      "source": [
        "# ZOO"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jkWRrunAMF_A"
      },
      "id": "jkWRrunAMF_A"
    },
    {
      "cell_type": "markdown",
      "id": "f830b5cc-4c67-47e1-8bcd-a66887c37c13",
      "metadata": {
        "id": "f830b5cc-4c67-47e1-8bcd-a66887c37c13"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bce89d7-817b-458f-bcb3-bac040d119a3",
      "metadata": {
        "id": "3bce89d7-817b-458f-bcb3-bac040d119a3"
      },
      "outputs": [],
      "source": [
        "#import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7899b1d5-5b04-4b10-babc-2537a505f179",
      "metadata": {
        "id": "7899b1d5-5b04-4b10-babc-2537a505f179"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f27c4dde-2737-4bff-bff6-d3f6d26171ed",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "1aa9820c01fd4fd0b08a0a9418291cd8"
          ]
        },
        "id": "f27c4dde-2737-4bff-bff6-d3f6d26171ed",
        "outputId": "a6d74a30-befe-4898-9e1e-bdfd256ade30"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1aa9820c01fd4fd0b08a0a9418291cd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ZOO:   0%|          | 0/12268 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Adversarial Samples:\n",
            "Accuracy: 0.8921611672644278\n",
            "F1 Score: 0.89632081205472544\n",
            "Detection Rate : 0.8796401335761991\n",
            "Precision: 0.8896085234723315\n",
            "Recall: 0.879801335761991\n",
            "AUC Score: 0.8693583100622055\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.89      4033\n",
            "           1       0.88      0.88      0.88      8235\n",
            "\n",
            "    accuracy                           0.89     12268\n",
            "   macro avg       0.87      0.88      0.88     12268\n",
            "weighted avg       0.88      0.87      0.89     12268\n",
            "\n",
            "Adversarial samples saved at: adversarial_sampless.csv\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, precision_recall_fscore_support\n",
        "from art.attacks.evasion import ZooAttack\n",
        "from art.estimators.classification import SklearnClassifier\n",
        "\n",
        "class ThompsonSamplingMultiArmedBandit:\n",
        "    def __init__(self, n_arms):\n",
        "        self.n_arms = n_arms\n",
        "        self.alpha = np.ones(n_arms)  # Initialize alpha parameters to 1\n",
        "        self.beta = np.ones(n_arms)   # Initialize beta parameters to 1\n",
        "\n",
        "    def choose_arm(self):\n",
        "        samples = np.random.beta(self.alpha, self.beta)  # Thompson sampling\n",
        "        return np.argmax(samples)\n",
        "\n",
        "    def update(self, arm, reward):\n",
        "        if reward == 1:\n",
        "            self.alpha[arm] += 1\n",
        "        else:\n",
        "            self.beta[arm] += 1\n",
        "\n",
        "# Load the extracted features and labels from the CSV file\n",
        "extracted_features_path = r\"E:\\train\\encoded_features_2017_18.csv\"\n",
        "df_extracted_features = pd.read_csv(extracted_features_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X = df_extracted_features.drop(columns=['Label'])\n",
        "y = df_extracted_features['Label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Multi-Armed Bandit\n",
        "n_arms = len(np.unique(y_train))  # Number of unique classes\n",
        "bandit = ThompsonSamplingMultiArmedBandit(n_arms)\n",
        "\n",
        "# Train the Multi-Armed Bandit\n",
        "for _ in range(len(X_train)):\n",
        "    arm = bandit.choose_arm()\n",
        "    reward = 1 if y_train.iloc[_] == arm else 0\n",
        "    bandit.update(arm, reward)\n",
        "\n",
        "# Initialize the Random Forest classifier\n",
        "random_forest_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest classifier\n",
        "random_forest_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Initialize ART classifier for the Random Forest model\n",
        "art_classifier = SklearnClassifier(model=random_forest_classifier)\n",
        "\n",
        "# Convert X_test to numpy array\n",
        "X_test_np = X_test.to_numpy()\n",
        "\n",
        "# ZOO attack to generate adversarial samples\n",
        "zoo = ZooAttack(classifier=art_classifier, max_iter=100, learning_rate=0.1, targeted=False, nb_parallel=1)\n",
        "X_test_adv = zoo.generate(X_test_np)\n",
        "\n",
        "# Save the adversarial samples to a CSV file\n",
        "adversarial_samples_path = \"adversarial_sampless.csv\"\n",
        "pd.DataFrame(X_test_adv).to_csv(adversarial_samples_path, index=False)\n",
        "\n",
        "# Predict probabilities on the adversarial testing set\n",
        "y_pred_proba_adv = random_forest_classifier.predict_proba(X_test_adv)[:, 1]\n",
        "\n",
        "# Threshold the probabilities to get binary predictions\n",
        "threshold = 0.5\n",
        "y_pred_adv = (y_pred_proba_adv > threshold).astype(int)\n",
        "\n",
        "# Evaluate the model on adversarial samples\n",
        "accuracy_adv = accuracy_score(y_test, y_pred_adv)\n",
        "classification_rep_adv = classification_report(y_test, y_pred_adv)\n",
        "auc_score_adv = roc_auc_score(y_test, y_pred_proba_adv)\n",
        "\n",
        "# Parse classification report to get F1 score and detection rate\n",
        "classification_dict_adv = classification_report(y_test, y_pred_adv, output_dict=True)\n",
        "f1_score_adv = classification_dict_adv['1']['f1-score']\n",
        "detection_rate_adv = classification_dict_adv['1']['recall']\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision_adv, recall_adv, _, _ = precision_recall_fscore_support(y_test, y_pred_adv, average='binary')\n",
        "\n",
        "# Print the evaluation metrics on adversarial samples\n",
        "print(\"Evaluation Metrics on Adversarial Samples:\")\n",
        "print(f\"Accuracy: {accuracy_adv}\")\n",
        "print(f\"F1 Score: {f1_score_adv}\")\n",
        "print(f\"Detection Rate : {detection_rate_adv}\")\n",
        "print(f\"Precision: {precision_adv}\")\n",
        "print(f\"Recall: {recall_adv}\")\n",
        "print(f\"AUC Score: {auc_score_adv}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep_adv)\n",
        "\n",
        "# Print the path of the saved adversarial samples\n",
        "print(f\"Adversarial samples saved at: {adversarial_samples_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef4690c0-2dd1-4600-8d1d-b4973a264c47",
      "metadata": {
        "id": "ef4690c0-2dd1-4600-8d1d-b4973a264c47"
      },
      "source": [
        "# LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2541eae1-af4e-466e-ae77-be18f4f09561",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "fdcc0dd8d47d4b5aa0985c7f86a01710"
          ]
        },
        "id": "2541eae1-af4e-466e-ae77-be18f4f09561",
        "outputId": "b3751e4c-aa3f-456a-e58b-9918543525d6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fdcc0dd8d47d4b5aa0985c7f86a01710",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ZOO:   0%|          | 0/12268 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Adversarial Samples:\n",
            "Accuracy: 0.5923540919465276\n",
            "F1 Score: 0.6522978516303971\n",
            "Detection Rate : 0.5696417729204615\n",
            "Precision: 0.7630123617436565\n",
            "Recall: 0.5696417729204615\n",
            "AUC Score: 0.6531093283086065\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.64      0.51      4033\n",
            "           1       0.76      0.57      0.65      8235\n",
            "\n",
            "    accuracy                           0.59     12268\n",
            "   macro avg       0.59      0.60      0.58     12268\n",
            "weighted avg       0.65      0.59      0.60     12268\n",
            "\n",
            "Adversarial samples saved at: adversarial_samples.csv\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, precision_recall_fscore_support\n",
        "from art.attacks.evasion import ZooAttack\n",
        "from art.estimators.classification import SklearnClassifier\n",
        "\n",
        "class ThompsonSamplingMultiArmedBandit:\n",
        "    def __init__(self, n_arms):\n",
        "        self.n_arms = n_arms\n",
        "        self.alpha = np.ones(n_arms)  # Initialize alpha parameters to 1\n",
        "        self.beta = np.ones(n_arms)   # Initialize beta parameters to 1\n",
        "\n",
        "    def choose_arm(self):\n",
        "        samples = np.random.beta(self.alpha, self.beta)  # Thompson sampling\n",
        "        return np.argmax(samples)\n",
        "\n",
        "    def update(self, arm, reward):\n",
        "        if reward == 1:\n",
        "            self.alpha[arm] += 1\n",
        "        else:\n",
        "            self.beta[arm] += 1\n",
        "\n",
        "# Load the extracted features and labels from the CSV file\n",
        "extracted_features_path = r\"E:\\train\\encoded_features_2017_18.csv\"\n",
        "df_extracted_features = pd.read_csv(extracted_features_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X = df_extracted_features.drop(columns=['Label'])\n",
        "y = df_extracted_features['Label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Multi-Armed Bandit\n",
        "n_arms = len(np.unique(y_train))  # Number of unique classes\n",
        "bandit = ThompsonSamplingMultiArmedBandit(n_arms)\n",
        "\n",
        "# Train the Multi-Armed Bandit\n",
        "for _ in range(len(X_train)):\n",
        "    arm = bandit.choose_arm()\n",
        "    reward = 1 if y_train.iloc[_] == arm else 0\n",
        "    bandit.update(arm, reward)\n",
        "\n",
        "# Initialize the Logistic Regression classifier\n",
        "logistic_regression_classifier = LogisticRegression(random_state=42)\n",
        "\n",
        "# Train the Logistic Regression classifier\n",
        "logistic_regression_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Initialize ART classifier for the Logistic Regression model\n",
        "art_classifier = SklearnClassifier(model=logistic_regression_classifier)\n",
        "\n",
        "# Convert X_test to numpy array\n",
        "X_test_np = X_test.to_numpy()\n",
        "\n",
        "# ZOO attack to generate adversarial samples\n",
        "zoo = ZooAttack(classifier=art_classifier, max_iter=100, learning_rate=0.1, targeted=False, nb_parallel=1)\n",
        "X_test_adv = zoo.generate(X_test_np)\n",
        "\n",
        "# Save the adversarial samples to a CSV file\n",
        "adversarial_samples_path = \"adversarial_samples.csv\"\n",
        "pd.DataFrame(X_test_adv).to_csv(adversarial_samples_path, index=False)\n",
        "\n",
        "# Predict probabilities on the adversarial testing set\n",
        "y_pred_proba_adv = logistic_regression_classifier.predict_proba(X_test_adv)[:, 1]\n",
        "\n",
        "# Threshold the probabilities to get binary predictions\n",
        "threshold = 0.5\n",
        "y_pred_adv = (y_pred_proba_adv > threshold).astype(int)\n",
        "\n",
        "# Evaluate the model on adversarial samples\n",
        "accuracy_adv = accuracy_score(y_test, y_pred_adv)\n",
        "classification_rep_adv = classification_report(y_test, y_pred_adv)\n",
        "auc_score_adv = roc_auc_score(y_test, y_pred_proba_adv)\n",
        "\n",
        "# Parse classification report to get F1 score and detection rate\n",
        "classification_dict_adv = classification_report(y_test, y_pred_adv, output_dict=True)\n",
        "f1_score_adv = classification_dict_adv['1']['f1-score']\n",
        "detection_rate_adv = classification_dict_adv['1']['recall']\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision_adv, recall_adv, _, _ = precision_recall_fscore_support(y_test, y_pred_adv, average='binary')\n",
        "\n",
        "# Print the evaluation metrics on adversarial samples\n",
        "print(\"Evaluation Metrics on Adversarial Samples:\")\n",
        "print(f\"Accuracy: {accuracy_adv}\")\n",
        "print(f\"F1 Score: {f1_score_adv}\")\n",
        "print(f\"Detection Rate : {detection_rate_adv}\")\n",
        "print(f\"Precision: {precision_adv}\")\n",
        "print(f\"Recall: {recall_adv}\")\n",
        "print(f\"AUC Score: {auc_score_adv}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep_adv)\n",
        "\n",
        "# Print the path of the saved adversarial samples\n",
        "print(f\"Adversarial samples saved at: {adversarial_samples_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0139b33-507c-49f0-8ffc-699a9aaf5dc6",
      "metadata": {
        "id": "c0139b33-507c-49f0-8ffc-699a9aaf5dc6"
      },
      "source": [
        "# Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a90e6eae-5531-48b1-b85c-310e7594d5b5",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "8feb97d31c3f4fa2bf1d5713f7a71608"
          ]
        },
        "id": "a90e6eae-5531-48b1-b85c-310e7594d5b5",
        "outputId": "f6fe0aa7-30fb-4f20-9206-3f4d677cd2b9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8feb97d31c3f4fa2bf1d5713f7a71608",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ZOO:   0%|          | 0/11913 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Adversarial Samples:\n",
            "Accuracy: 0.6967178712331067\n",
            "F1 Score: 0.67683500962978814\n",
            "Detection Rate : 0.8862876254180602\n",
            "Precision: 0.61006134969325153\n",
            "Recall: 0.8862876254180602\n",
            "AUC Score: 0.7919915405158158\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.88      0.67     11315\n",
            "           1       0.61      0.87      0.67       598\n",
            "\n",
            "    accuracy                           0.69     11913\n",
            "   macro avg       0.69      0.70      0.68     11913\n",
            "weighted avg       0.95      0.69      0.69     11913\n",
            "\n",
            "Adversarial samples saved at: adversarial_samplees.csv\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, precision_recall_fscore_support\n",
        "from art.attacks.evasion import ZooAttack\n",
        "from art.estimators.classification import SklearnClassifier\n",
        "\n",
        "class ThompsonSamplingMultiArmedBandit:\n",
        "    def __init__(self, n_arms):\n",
        "        self.n_arms = n_arms\n",
        "        self.alpha = np.ones(n_arms)  # Initialize alpha parameters to 1\n",
        "        self.beta = np.ones(n_arms)   # Initialize beta parameters to 1\n",
        "\n",
        "    def choose_arm(self):\n",
        "        samples = np.random.beta(self.alpha, self.beta)  # Thompson sampling\n",
        "        return np.argmax(samples)\n",
        "\n",
        "    def update(self, arm, reward):\n",
        "        if reward == 1:\n",
        "            self.alpha[arm] += 1\n",
        "        else:\n",
        "            self.beta[arm] += 1\n",
        "\n",
        "# Load the extracted features and labels from the CSV file\n",
        "extracted_features_path = r\"E:\\train\\encoded_features_2017_18.csv\"\n",
        "df_extracted_features = pd.read_csv(extracted_features_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X = df_extracted_features.drop(columns=['Label'])\n",
        "y = df_extracted_features['Label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the Multi-Armed Bandit\n",
        "n_arms = len(np.unique(y_train))  # Number of unique classes\n",
        "bandit = ThompsonSamplingMultiArmedBandit(n_arms)\n",
        "\n",
        "# Train the Multi-Armed Bandit\n",
        "for _ in range(len(X_train)):\n",
        "    arm = bandit.choose_arm()\n",
        "    reward = 1 if y_train.iloc[_] == arm else 0\n",
        "    bandit.update(arm, reward)\n",
        "\n",
        "# Initialize the Support Vector Machine (SVM) classifier\n",
        "svm_classifier = SVC(probability=True, random_state=42)\n",
        "\n",
        "# Train the SVM classifier\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Initialize ART classifier for the SVM model\n",
        "art_classifier = SklearnClassifier(model=svm_classifier)\n",
        "\n",
        "# Convert X_test to numpy array\n",
        "X_test_np = X_test.to_numpy()\n",
        "\n",
        "# ZOO attack to generate adversarial samples\n",
        "zoo = ZooAttack(classifier=art_classifier, max_iter=100, learning_rate=0.1, targeted=False, nb_parallel=1)\n",
        "X_test_adv = zoo.generate(X_test_np)\n",
        "\n",
        "# Save the adversarial samples to a CSV file\n",
        "adversarial_samples_path = \"adversarial_samplees.csv\"\n",
        "pd.DataFrame(X_test_adv).to_csv(adversarial_samples_path, index=False)\n",
        "\n",
        "# Predict probabilities on the adversarial testing set\n",
        "y_pred_proba_adv = svm_classifier.predict_proba(X_test_adv)[:, 1]\n",
        "\n",
        "# Threshold the probabilities to get binary predictions\n",
        "threshold = 0.5\n",
        "y_pred_adv = (y_pred_proba_adv > threshold).astype(int)\n",
        "\n",
        "# Evaluate the model on adversarial samples\n",
        "accuracy_adv = accuracy_score(y_test, y_pred_adv)\n",
        "classification_rep_adv = classification_report(y_test, y_pred_adv)\n",
        "auc_score_adv = roc_auc_score(y_test, y_pred_proba_adv)\n",
        "\n",
        "# Parse classification report to get F1 score and detection rate\n",
        "classification_dict_adv = classification_report(y_test, y_pred_adv, output_dict=True)\n",
        "f1_score_adv = classification_dict_adv['1']['f1-score']\n",
        "detection_rate_adv = classification_dict_adv['1']['recall']\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision_adv, recall_adv, _, _ = precision_recall_fscore_support(y_test, y_pred_adv, average='binary')\n",
        "\n",
        "# Print the evaluation metrics on adversarial samples\n",
        "print(\"Evaluation Metrics on Adversarial Samples:\")\n",
        "print(f\"Accuracy: {accuracy_adv}\")\n",
        "print(f\"F1 Score: {f1_score_adv}\")\n",
        "print(f\"Detection Rate : {detection_rate_adv}\")\n",
        "print(f\"Precision: {precision_adv}\")\n",
        "print(f\"Recall: {recall_adv}\")\n",
        "print(f\"AUC Score: {auc_score_adv}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep_adv)\n",
        "\n",
        "# Print the path of the saved adversarial samples\n",
        "print(f\"Adversarial samples saved at: {adversarial_samples_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86766003-bfc9-4bb0-bf5b-1e8d88cdbe3a",
      "metadata": {
        "id": "86766003-bfc9-4bb0-bf5b-1e8d88cdbe3a"
      },
      "source": [
        "# DNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "528f4329-1c1d-4f7a-aea5-ef02148db7de",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "3399462d7b94420289d1e545fd6702cf"
          ]
        },
        "id": "528f4329-1c1d-4f7a-aea5-ef02148db7de",
        "outputId": "37790d79-f8d2-4bbc-87e5-a334e5c6f29a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train on 49068 samples\n",
            "Epoch 1/10\n",
            "49068/49068 [==============================] - 2s 42us/sample - loss: 0.1944 - accuracy: 0.9329\n",
            "Epoch 2/10\n",
            "49068/49068 [==============================] - 2s 40us/sample - loss: 0.1007 - accuracy: 0.9711\n",
            "Epoch 3/10\n",
            "49068/49068 [==============================] - 2s 39us/sample - loss: 0.0816 - accuracy: 0.9756\n",
            "Epoch 4/10\n",
            "49068/49068 [==============================] - 2s 39us/sample - loss: 0.0693 - accuracy: 0.9790\n",
            "Epoch 5/10\n",
            "49068/49068 [==============================] - 2s 42us/sample - loss: 0.0657 - accuracy: 0.9801\n",
            "Epoch 6/10\n",
            "49068/49068 [==============================] - 2s 42us/sample - loss: 0.0589 - accuracy: 0.9817\n",
            "Epoch 7/10\n",
            "49068/49068 [==============================] - 2s 39us/sample - loss: 0.0598 - accuracy: 0.9821\n",
            "Epoch 8/10\n",
            "49068/49068 [==============================] - 2s 39us/sample - loss: 0.0508 - accuracy: 0.9828\n",
            "Epoch 9/10\n",
            "49068/49068 [==============================] - 2s 39us/sample - loss: 0.0518 - accuracy: 0.9830\n",
            "Epoch 10/10\n",
            "49068/49068 [==============================] - 2s 42us/sample - loss: 0.0454 - accuracy: 0.9841\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3399462d7b94420289d1e545fd6702cf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ZOO:   0%|          | 0/12268 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Metrics on Adversarial Samples:\n",
            "Accuracy: 0.47334528855559177\n",
            "F1 Score: 0.3803586841852882\n",
            "Detection Rate : 0.24080145719489982\n",
            "Precision: 0.9046532846715328\n",
            "Recall: 0.24080145719489982\n",
            "AUC Score: 0.5664305605048574\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.95      0.54      4033\n",
            "           1       0.90      0.24      0.38      8235\n",
            "\n",
            "    accuracy                           0.47     12268\n",
            "   macro avg       0.64      0.59      0.46     12268\n",
            "weighted avg       0.73      0.47      0.43     12268\n",
            "\n",
            "Adversarial samples saved at: adversariall_samples.csv\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, precision_recall_fscore_support\n",
        "from art.attacks.evasion import ZooAttack\n",
        "from art.estimators.classification import KerasClassifier\n",
        "\n",
        "# Disable eager execution in TensorFlow\n",
        "tf.compat.v1.disable_eager_execution()\n",
        "\n",
        "class ThompsonSamplingMultiArmedBandit:\n",
        "    def __init__(self, n_arms):\n",
        "        self.n_arms = n_arms\n",
        "        self.alpha = np.ones(n_arms)  # Initialize alpha parameters to 1\n",
        "        self.beta = np.ones(n_arms)   # Initialize beta parameters to 1\n",
        "\n",
        "    def choose_arm(self):\n",
        "        samples = np.random.beta(self.alpha, self.beta)  # Thompson sampling\n",
        "        return np.argmax(samples)\n",
        "\n",
        "    def update(self, arm, reward):\n",
        "        if reward == 1:\n",
        "            self.alpha[arm] += 1\n",
        "        else:\n",
        "            self.beta[arm] += 1\n",
        "\n",
        "# Load the extracted features and labels from the CSV file\n",
        "extracted_features_path = r\"E:\\train\\encoded_features_2017_18.csv\"\n",
        "df_extracted_features = pd.read_csv(extracted_features_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X = df_extracted_features.drop(columns=['Label'])\n",
        "y = df_extracted_features['Label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the DNN model with multi-output (2 neurons for binary classification)\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(128, input_shape=(X_train.shape[1],), activation='relu'),\n",
        "    keras.layers.Dense(64, activation='relu'),\n",
        "    keras.layers.Dense(2, activation='softmax')  # Two output neurons for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',  # Use categorical crossentropy for multi-output\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Initialize the Multi-Armed Bandit\n",
        "n_arms = len(np.unique(y_train))  # Number of unique classes\n",
        "bandit = ThompsonSamplingMultiArmedBandit(n_arms)\n",
        "\n",
        "# Train the Multi-Armed Bandit\n",
        "for _ in range(len(X_train)):\n",
        "    arm = bandit.choose_arm()\n",
        "    reward = 1 if y_train.iloc[_] == arm else 0\n",
        "    bandit.update(arm, reward)\n",
        "\n",
        "# Convert labels to one-hot encoding for multi-output\n",
        "y_train_onehot = keras.utils.to_categorical(y_train, num_classes=2)\n",
        "\n",
        "# Train the DNN model\n",
        "model.fit(X_train, y_train_onehot, epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Initialize ART classifier for the DNN model\n",
        "art_classifier = KerasClassifier(model=model, clip_values=(0, 1))\n",
        "\n",
        "# Convert X_test to numpy array\n",
        "X_test_np = X_test.to_numpy()\n",
        "\n",
        "# ZOO attack to generate adversarial samples\n",
        "zoo = ZooAttack(classifier=art_classifier, max_iter=100, learning_rate=0.1, targeted=False, nb_parallel=1)\n",
        "X_test_adv = zoo.generate(X_test_np)\n",
        "\n",
        "# Save the adversarial samples to a CSV file\n",
        "adversarial_samples_path = \"adversariall_samples.csv\"\n",
        "pd.DataFrame(X_test_adv).to_csv(adversarial_samples_path, index=False)\n",
        "\n",
        "# Predict probabilities on the adversarial testing set\n",
        "y_pred_proba_adv = model.predict(X_test_adv)\n",
        "\n",
        "# Threshold the probabilities to get binary predictions\n",
        "y_pred_adv = np.argmax(y_pred_proba_adv, axis=1)\n",
        "\n",
        "# Evaluate the model on adversarial samples\n",
        "accuracy_adv = accuracy_score(y_test, y_pred_adv)\n",
        "classification_rep_adv = classification_report(y_test, y_pred_adv)\n",
        "auc_score_adv = roc_auc_score(y_test, y_pred_proba_adv[:, 1])\n",
        "\n",
        "# Parse classification report to get F1 score and detection rate\n",
        "classification_dict_adv = classification_report(y_test, y_pred_adv, output_dict=True)\n",
        "f1_score_adv = classification_dict_adv['1']['f1-score']\n",
        "detection_rate_adv = classification_dict_adv['1']['recall']\n",
        "\n",
        "# Calculate precision, recall, and F1 score\n",
        "precision_adv, recall_adv, _, _ = precision_recall_fscore_support(y_test, y_pred_adv, average='binary')\n",
        "\n",
        "# Print the evaluation metrics on adversarial samples\n",
        "print(\"Evaluation Metrics on Adversarial Samples:\")\n",
        "print(f\"Accuracy: {accuracy_adv}\")\n",
        "print(f\"F1 Score: {f1_score_adv}\")\n",
        "print(f\"Detection Rate : {detection_rate_adv}\")\n",
        "print(f\"Precision: {precision_adv}\")\n",
        "print(f\"Recall: {recall_adv}\")\n",
        "print(f\"AUC Score: {auc_score_adv}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep_adv)\n",
        "\n",
        "# Print the path of the saved adversarial samples\n",
        "print(f\"Adversarial samples saved at: {adversarial_samples_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f16f100-9a9e-4e36-9b72-4171b2251d12",
      "metadata": {
        "id": "1f16f100-9a9e-4e36-9b72-4171b2251d12"
      },
      "source": [
        "# IDS-Anta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31a86cee-8341-47b1-a34a-deb68ab63493",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "8f9dbc4afbd545ebac9fd9e113b5e98a"
          ]
        },
        "id": "31a86cee-8341-47b1-a34a-deb68ab63493",
        "outputId": "77da3420-2598-4ff7-f61a-310012083251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "373/373 [==============================] - 1s 1ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8f9dbc4afbd545ebac9fd9e113b5e98a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "ZOO:   0%|          | 0/11913 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy (Adversarial): 0.9498027365063376\n",
            "Classification Report (Adversarial):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97     11315\n",
            "           1       0.00      0.00      0.00       598\n",
            "\n",
            "    accuracy                           0.95     11913\n",
            "   macro avg       0.47      0.50      0.49     11913\n",
            "weighted avg       0.90      0.95      0.93     11913\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from collections import defaultdict\n",
        "from art.estimators.classification import SklearnClassifier\n",
        "from art.attacks.evasion import ZooAttack\n",
        "\n",
        "class MultiArmedBanditThompsonSampling:\n",
        "    def __init__(self, num_classifiers):\n",
        "        self.num_classifiers = num_classifiers\n",
        "        self.successes = defaultdict(int)\n",
        "        self.failures = defaultdict(int)\n",
        "        self.selected_classifier = None\n",
        "\n",
        "    def select_classifier(self):\n",
        "        max_ucb = -float('inf')\n",
        "        for clf in range(self.num_classifiers):\n",
        "            beta_sample = np.random.beta(self.successes[clf] + 1, self.failures[clf] + 1)\n",
        "            if beta_sample > max_ucb:\n",
        "                max_ucb = beta_sample\n",
        "                self.selected_classifier = clf\n",
        "        return self.selected_classifier\n",
        "\n",
        "    def update(self, clf_index, success):\n",
        "        if success:\n",
        "            self.successes[clf_index] += 1\n",
        "        else:\n",
        "            self.failures[clf_index] += 1\n",
        "\n",
        "# Load the extracted features and labels from the CSV file\n",
        "extracted_features_path = r\"E:\\train\\encoded_features_2017_18.csv\"\n",
        "df_extracted_features = pd.read_csv(extracted_features_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X = df_extracted_features.drop(columns=['Label'])\n",
        "y = df_extracted_features['Label']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Taining we use the 2017&18 Data and testing we take the 2017 adversial data\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Implement ACO\n",
        "class AntColony:\n",
        "    def __init__(self, num_ants, num_iterations, num_features):\n",
        "        self.num_ants = num_ants\n",
        "        self.num_iterations = num_iterations\n",
        "        self.num_features = num_features\n",
        "\n",
        "    def select_features(self, X_train, y_train):\n",
        "        # Implement feature selection using ACO\n",
        "        # For simplicity, we'll randomly select features\n",
        "        return np.random.choice(range(self.num_features), size=self.num_features // 2, replace=False)\n",
        "\n",
        "# Initialize ACO\n",
        "aco = AntColony(num_ants=10, num_iterations=50, num_features=X_train.shape[1])\n",
        "# Select features using ACO\n",
        "selected_features = aco.select_features(X_train, y_train)\n",
        "\n",
        "# Extract selected features from the training and testing sets\n",
        "X_train_aco = X_train.iloc[:, selected_features]\n",
        "X_test_aco = X_test.iloc[:, selected_features]\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = [\n",
        "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    LogisticRegression(max_iter=1000, random_state=42),\n",
        "    SVC(kernel='linear', random_state=42),\n",
        "    tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_aco.shape[1],)),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')\n",
        "    ])\n",
        "]\n",
        "\n",
        "# Initialize Thompson Sampling Multi-Armed Bandit\n",
        "bandit = MultiArmedBanditThompsonSampling(num_classifiers=len(classifiers))\n",
        "\n",
        "# Perform Thompson Sampling for a fixed number of rounds\n",
        "num_rounds = 1000\n",
        "for round in range(num_rounds):\n",
        "    selected_clf_index = bandit.select_classifier()\n",
        "    selected_clf = classifiers[selected_clf_index]\n",
        "\n",
        "    if isinstance(selected_clf, tf.keras.Sequential):\n",
        "        # Compile and train the DNN model\n",
        "        selected_clf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "        selected_clf.fit(X_train_aco, y_train, epochs=10, batch_size=32, validation_data=(X_test_aco, y_test), verbose=0)\n",
        "        y_pred_probs = selected_clf.predict(X_test_aco)\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    else:\n",
        "        # Train the classifier\n",
        "        selected_clf.fit(X_train_aco, y_train)\n",
        "        y_pred = selected_clf.predict(X_test_aco)\n",
        "\n",
        "    # Evaluate the selected classifier and update the bandit\n",
        "    report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
        "    accuracy = report['accuracy']\n",
        "    bandit.update(selected_clf_index, accuracy)\n",
        "\n",
        "# Generate a classification report for the classifier\n",
        "best_clf_index = max(bandit.successes, key=bandit.successes.get)\n",
        "best_clf = classifiers[best_clf_index]\n",
        "\n",
        "if isinstance(best_clf, tf.keras.Sequential):\n",
        "    best_clf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    best_clf.fit(X_train_aco, y_train, epochs=10, batch_size=32, validation_data=(X_test_aco, y_test), verbose=0)\n",
        "    y_pred_probs = best_clf.predict(X_test_aco)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "else:\n",
        "    best_clf.fit(X_train_aco, y_train)\n",
        "    y_pred = best_clf.predict(X_test_aco)\n",
        "\n",
        "# Generate classification report for the classifier\n",
        "target_names = [str(class_name) for class_name in label_encoder.classes_]\n",
        "report = classification_report(y_test, y_pred, target_names=target_names)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Adversarial attack using ZooAttack (Zeroth-order Optimization Attack)\n",
        "best_clf_art = SklearnClassifier(model=best_clf, clip_values=(0, 1))\n",
        "attack = ZooAttack(classifier=best_clf_art, max_iter=100, learning_rate=1e-2, targeted=False, use_resize=False, nb_parallel=5)\n",
        "\n",
        "# Convert data to NumPy array\n",
        "X_test_np = X_test_aco.to_numpy()\n",
        "\n",
        "X_test_adv = attack.generate(X_test_np)\n",
        "y_pred_adv = best_clf_art.predict(X_test_adv)\n",
        "\n",
        "# Flatten the y_test array\n",
        "y_test_flat = y_test if len(y_test.shape) == 1 else np.argmax(y_test, axis=1)\n",
        "\n",
        "# Flatten the y_pred_adv array\n",
        "y_pred_adv_flat = np.argmax(y_pred_adv, axis=1)\n",
        "\n",
        "# Generate the classification report for the adversarial attack\n",
        "report_adv = classification_report(y_test_flat, y_pred_adv_flat, target_names=target_names)\n",
        "\n",
        "# Calculate the accuracy for the adversarial attack\n",
        "test_accuracy_adv = accuracy_score(y_test_flat, y_pred_adv_flat)\n",
        "print(\"Test Accuracy (Adversarial):\", test_accuracy_adv)\n",
        "\n",
        "# Print the classification report\n",
        "print(\"Classification Report (Adversarial):\\n\", report_adv)\n",
        "\n",
        "# Save the generated adversarial samples to a CSV file\n",
        "output_directory = r\"E:\\train\"\n",
        "np.savetxt(output_directory + \"/adversarial_samplles.csv\", X_test_adv, delimiter=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5a419b6-fb1d-4a1c-9512-0cf8b2ae3738",
      "metadata": {
        "id": "d5a419b6-fb1d-4a1c-9512-0cf8b2ae3738",
        "outputId": "87f2b7c5-091a-4d77-ce09-f5f7164cdd87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adversarial Metrics:\n",
            "Precision: 0.9021252382749273\n",
            "Recall: 0.9498027365063376\n",
            "F1-score: 0.9253502637824359\n",
            "Detection Rate : 0.9498027365063376\n",
            "AUC Score: 0.969884\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    # Calculate Precision, Recall, F1-score\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    # Calculate Detection Rate (True Positive Rate)\n",
        "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "    detection_rate = conf_matrix.diagonal() / conf_matrix.sum(axis=1)\n",
        "\n",
        "    # Calculate AUC Score\n",
        "    auc_score = roc_auc_score(y_true, y_pred, average='weighted', multi_class='ovr')\n",
        "\n",
        "    return precision, recall, f1, detection_rate, auc_score\n",
        "\n",
        "# Evaluate adversarial case\n",
        "precision_adv, recall_adv, f1_adv, detection_rate_adv, auc_score_adv = evaluate_model(y_test_flat, y_pred_adv_flat)\n",
        "\n",
        "# Print adversarial metrics\n",
        "print(\"Adversarial Metrics:\")\n",
        "print(\"Precision:\", precision_adv)\n",
        "print(\"Recall:\", recall_adv)\n",
        "print(\"F1-score:\", f1_adv)\n",
        "print(\"Detection Rate :\", detection_rate_adv)\n",
        "print(\"AUC Score:\", auc_score_adv)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "e559b121-7a25-4c95-ada7-68161fe26313"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
