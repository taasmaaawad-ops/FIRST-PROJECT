{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taasmaaawad-ops/FIRST-PROJECT/blob/main/Adversarial%20Scenario/FGSM-adversarial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "wW_sT9iNibWX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "w073GqQRDlga",
        "outputId": "3e86c9d2-4420-469c-c420-ddd78a7f77b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'FIRST-PROJECT'...\n",
            "remote: Enumerating objects: 75, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (74/74), done.\u001b[K\n",
            "remote: Total 75 (delta 33), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (75/75), 13.09 MiB | 5.17 MiB/s, done.\n",
            "Resolving deltas: 100% (33/33), done.\n",
            "/content/FIRST-PROJECT\n"
          ]
        }
      ],
      "source": [
        "#import packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# to link folder in github\n",
        "!git clone https://github.com/taasmaaawad-ops/FIRST-PROJECT.git\n",
        "%cd FIRST-PROJECT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from collections import defaultdict\n",
        "\n",
        "class MultiArmedBanditThompsonSampling:\n",
        "    def __init__(self, num_classifiers):\n",
        "        self.num_classifiers = num_classifiers\n",
        "        self.successes = defaultdict(int)\n",
        "        self.failures = defaultdict(int)\n",
        "        self.selected_classifier = None\n",
        "\n",
        "    def select_classifier(self):\n",
        "        max_ucb = -float('inf')\n",
        "        for clf in range(self.num_classifiers):\n",
        "            beta_sample = np.random.beta(self.successes[clf] + 1, self.failures[clf] + 1)\n",
        "            if beta_sample > max_ucb:\n",
        "                max_ucb = beta_sample\n",
        "                self.selected_classifier = clf\n",
        "        return self.selected_classifier\n",
        "\n",
        "    def update(self, clf_index, success):\n",
        "        if success:\n",
        "            self.successes[clf_index] += 1\n",
        "        else:\n",
        "            self.failures[clf_index] += 1\n",
        "\n",
        "# Load the extracted features and labels from the CSV file\n",
        "extracted_features_path = r\"/content/FIRST-PROJECT/encoded_features_2017.csv\"\n",
        "df_extracted_features = pd.read_csv(extracted_features_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X = df_extracted_features.drop(columns=['Label'])\n",
        "y = df_extracted_features['Label']\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize classifiers\n",
        "classifiers = [\n",
        "    RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    LogisticRegression(max_iter=1000, random_state=42),\n",
        "    SVC(kernel='linear', random_state=42),\n",
        "    tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(len(label_encoder.classes_), activation='softmax')\n",
        "    ])\n",
        "]\n",
        "\n",
        "# Initialize Thompson Sampling Multi-Armed Bandit\n",
        "bandit = MultiArmedBanditThompsonSampling(num_classifiers=len(classifiers))\n",
        "\n",
        "# Perform Thompson Sampling for a fixed number of rounds\n",
        "num_rounds = 10\n",
        "for round in range(num_rounds):\n",
        "    selected_clf_index = bandit.select_classifier()\n",
        "    selected_clf = classifiers[selected_clf_index]\n",
        "\n",
        "    if isinstance(selected_clf, tf.keras.Sequential):\n",
        "        # Reshape and normalize data for DNN\n",
        "        X_train_dnn = np.array(X_train).reshape(-1, X_train.shape[1]).astype(np.float32) / 255.0\n",
        "        X_test_dnn = np.array(X_test).reshape(-1, X_test.shape[1]).astype(np.float32) / 255.0\n",
        "        # Compile the model\n",
        "        selected_clf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "        # Train the model\n",
        "        selected_clf.fit(X_train_dnn, y_train, epochs=10, batch_size=32, validation_data=(X_test_dnn, y_test), verbose=0)\n",
        "        # Predict on the testing set\n",
        "        y_pred_probs = selected_clf.predict(X_test_dnn)\n",
        "        y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "    else:\n",
        "        # Train the classifier\n",
        "        selected_clf.fit(X_train, y_train)\n",
        "        # Predict on the testing set\n",
        "        y_pred = selected_clf.predict(X_test)\n",
        "\n",
        "    # Evaluate the selected classifier and update the bandit\n",
        "    report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, output_dict=True)\n",
        "    accuracy = report['accuracy']\n",
        "    bandit.update(selected_clf_index, accuracy)\n",
        "\n",
        "# Generate a classification report for the best performing classifier\n",
        "best_clf_index = max(bandit.successes, key=bandit.successes.get)\n",
        "best_clf = classifiers[best_clf_index]\n",
        "\n",
        "if isinstance(best_clf, tf.keras.Sequential):\n",
        "    # Reshape and normalize data for DNN\n",
        "    X_train_dnn = np.array(X_train).reshape(-1, X_train.shape[1]).astype(np.float32) / 255.0\n",
        "    X_test_dnn = np.array(X_test).reshape(-1, X_test.shape[1]).astype(np.float32) / 255.0\n",
        "    # Compile the model\n",
        "    best_clf.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    # Train the model\n",
        "    best_clf.fit(X_train_dnn, y_train, epochs=10, batch_size=32, validation_data=(X_test_dnn, y_test), verbose=0)\n",
        "    # Predict on the testing set\n",
        "    y_pred_probs = best_clf.predict(X_test_dnn)\n",
        "    y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "else:\n",
        "    # Train the classifier\n",
        "    best_clf.fit(X_train, y_train)\n",
        "    # Predict on the testing set\n",
        "    y_pred = best_clf.predict(X_test)\n",
        "    # Convert label_encoder.classes_ to a list of strings\n",
        "    target_names = [str(class_name) for class_name in label_encoder.classes_]\n",
        "\n",
        "# Generate classification report for the best performing classifier\n",
        "report = classification_report(y_test, y_pred, target_names=target_names)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "DPfREuchDpkD",
        "outputId": "6c44cb29-5379-4d59-8f11-64ca4b382143"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/FIRST-PROJECT/encoded_features_2017.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2899791472.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Load the extracted features and labels from the CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mextracted_features_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"/content/FIRST-PROJECT/encoded_features_2017.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mdf_extracted_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_features_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Separate features and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/FIRST-PROJECT/encoded_features_2017.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "SWuW5WAMJ6oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support, roc_auc_score\n",
        "from art.estimators.classification import SklearnClassifier\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have trained the logistic regression model and have X_test and y_test ready\n",
        "# Assuming X_test and y_test are already defined\n",
        "\n",
        "# Step 1: Train a logistic regression model\n",
        "best_clf = LogisticRegression()\n",
        "best_clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 2: Convert X_test to NumPy array\n",
        "X_test_np = X_test.to_numpy()\n",
        "\n",
        "# Step 3: Generate adversarial examples using FGSM\n",
        "best_clf_art = SklearnClassifier(model=best_clf, clip_values=(0, 1))\n",
        "attack = FastGradientMethod(estimator=best_clf_art, eps=0.2)\n",
        "X_test_adv = attack.generate(X_test_np)\n",
        "\n",
        "# Step 4: Save the adversarial examples in a CSV file\n",
        "adversarial_df = pd.DataFrame(X_test_adv, columns=[f'feature_{i}' for i in range(X_test_adv.shape[1])])\n",
        "adversarial_df.to_csv('adversarial_examples_fgsml.csv', index=False)\n",
        "\n",
        "# Step 5: Evaluate the adversarial examples\n",
        "y_pred_adv = best_clf.predict(X_test_adv)\n",
        "precision_adv, recall_adv, f1_score_adv, _ = precision_recall_fscore_support(y_test, y_pred_adv, average='binary')\n",
        "auc_score_adv = roc_auc_score(y_test, y_pred_adv)\n",
        "test_accuracy_adv = accuracy_score(y_test, y_pred_adv)\n",
        "detection_rate_adv = recall_adv\n",
        "\n",
        "print(\"Adversarial Test Accuracy:\", test_accuracy_adv)\n",
        "print(\"Precision on adversarial examples:\", precision_adv)\n",
        "print(\"Recall on adversarial examples:\", recall_adv)\n",
        "print(\"F1 Score on adversarial examples:\", f1_score_adv)\n",
        "print(\"AUC Score on adversarial examples:\", auc_score_adv)\n",
        "print(\"Detection Rate on adversarial examples:\", detection_rate_adv)\n",
        "\n",
        "# Generate classification report for adversarial examples\n",
        "report_adv = classification_report(y_test, y_pred_adv, target_names=target_names)\n",
        "print(\"Adversarial Classification Report:\")\n",
        "print(report_adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYbftPanDpgE",
        "outputId": "5779fc11-b53b-49c7-892e-4b4b38c5e742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial Test Accuracy: 0.6621291164003913\n",
            "Precision on adversarial examples: 0.7147207055858883\n",
            "Recall on adversarial examples: 0.8265938069216757\n",
            "F1 Score on adversarial examples: 0.7665972183118419\n",
            "AUC Score on adversarial examples: 0.5764508831285791\n",
            "Detection Rate on adversarial examples: 0.8265938069216757\n",
            "Adversarial Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.33      0.39      4033\n",
            "           1       0.71      0.83      0.77      8235\n",
            "\n",
            "    accuracy                           0.66     12268\n",
            "   macro avg       0.60      0.58      0.58     12268\n",
            "weighted avg       0.64      0.66      0.64     12268\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "AFxvm3wvKMUo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support, roc_auc_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have trained the Random Forest model and have X_test and y_test ready\n",
        "# Assuming X_test and y_test are already defined\n",
        "\n",
        "# Step 1: Train a Random Forest model\n",
        "best_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "best_clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 2: Convert X_test to NumPy array\n",
        "X_test_np = X_test.to_numpy()\n",
        "\n",
        "# Step 3: Generate adversarial examples using FGSM\n",
        "best_clf_art = SklearnClassifier(model=best_clf, clip_values=(0, 1))\n",
        "attack = FastGradientMethod(estimator=best_clf_art, eps=0.2)\n",
        "X_test_adv = attack.generate(X_test_np)\n",
        "\n",
        "# Step 4: Save the adversarial examples in a CSV file\n",
        "adversarial_df = pd.DataFrame(X_test_adv, columns=[f'feature_{i}' for i in range(X_test_adv.shape[1])])\n",
        "adversarial_df.to_csv('adversarial_examples_fgsmrfl.csv', index=False)\n",
        "\n",
        "# Step 5: Evaluate the adversarial examples\n",
        "y_pred_adv = best_clf.predict(X_test_adv)\n",
        "precision_adv, recall_adv, f1_score_adv, _ = precision_recall_fscore_support(y_test, y_pred_adv, average='binary')\n",
        "auc_score_adv = roc_auc_score(y_test, y_pred_adv)\n",
        "test_accuracy_adv = accuracy_score(y_test, y_pred_adv)\n",
        "detection_rate_adv = recall_adv\n",
        "\n",
        "print(\"Adversarial Test Accuracy:\", test_accuracy_adv)\n",
        "print(\"Precision on adversarial examples:\", precision_adv)\n",
        "print(\"Recall on adversarial examples:\", recall_adv)\n",
        "print(\"F1 Score on adversarial examples:\", f1_score_adv)\n",
        "print(\"AUC Score on adversarial examples:\", auc_score_adv)\n",
        "print(\"Detection Rate on adversarial examples:\", detection_rate_adv)\n",
        "\n",
        "# Generate classification report for adversarial examples\n",
        "report_adv = classification_report(y_test, y_pred_adv, target_names=target_names)\n",
        "print(\"Adversarial Classification Report:\")\n",
        "print(report_adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3CgQKeXKUVq",
        "outputId": "2b57259f-ac00-4074-8228-d2d09ccc8f87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial Test Accuracy: 0.9569377990430622\n",
            "Precision on adversarial examples: 0.8195488721804511\n",
            "Recall on adversarial examples: 0.18227424749163879\n",
            "F1 Score on adversarial examples: 0.29822161422708615\n",
            "AUC Score on adversarial examples: 0.5900765846384398\n",
            "Detection Rate on adversarial examples: 0.18227424749163879\n",
            "Adversarial Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98     11315\n",
            "           1       0.82      0.18      0.30       598\n",
            "\n",
            "    accuracy                           0.96     11913\n",
            "   macro avg       0.89      0.59      0.64     11913\n",
            "weighted avg       0.95      0.96      0.94     11913\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "m6ogDWsmKYIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from art.estimators.classification import SklearnClassifier\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have trained the SVM model and have X_test_np and y_test ready\n",
        "\n",
        "# Step 1: Define your SVM model\n",
        "svm_model = SVC(kernel='rbf', gamma='scale', probability=True)  # Example SVM with radial basis function kernel\n",
        "\n",
        "# Step 2: Train your SVM model\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 3: Initialize a SklearnClassifier\n",
        "art_classifier_svm = SklearnClassifier(model=svm_model, clip_values=(0, 1))\n",
        "\n",
        "# Step 4: Generate adversarial examples using FGSM\n",
        "attack_svm = FastGradientMethod(estimator=art_classifier_svm, eps=0.2)\n",
        "X_test_adv_svm = attack_svm.generate(X_test_np)\n",
        "\n",
        "# Step 5: Save the adversarial examples in a CSV file\n",
        "adversarial_df_svm = pd.DataFrame(X_test_adv_svm, columns=[f'feature_{i}' for i in range(X_test_adv_svm.shape[1])])\n",
        "adversarial_df_svm.to_csv('adversarial_examples_fgsm_svm.csv', index=False)\n",
        "\n",
        "# Step 6: Evaluate the adversarial examples\n",
        "y_pred_adv_svm = svm_model.predict(X_test_adv_svm)\n",
        "report_adv_svm = classification_report(y_test, y_pred_adv_svm)\n",
        "test_accuracy_adv_svm = accuracy_score(y_test, y_pred_adv_svm)\n",
        "print(\"Adversarial Test Accuracy (SVM):\", test_accuracy_adv_svm)\n",
        "print(\"Adversarial Classification Report (SVM):\")\n",
        "print(report_adv_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVyWRVqGDpQG",
        "outputId": "a87d67d5-7d32-419c-fa22-3416d610549e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1227/1227 [==============================] - 6s 4ms/step - loss: 0.2451 - accuracy: 0.9179 - val_loss: 0.1209 - val_accuracy: 0.9665\n",
            "384/384 [==============================] - 1s 2ms/step\n",
            "Adversarial Test Accuracy (SVM): 0.7646723182262798\n",
            "Adversarial Classification Report (SVM):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.60      0.63      4033\n",
            "           1       0.81      0.84      0.83      8235\n",
            "\n",
            "    accuracy                           0.76     12268\n",
            "   macro avg       0.73      0.72      0.73     12268\n",
            "weighted avg       0.76      0.76      0.76     12268\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
        "from art.estimators.classification import SklearnClassifier\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have trained the SVM model and have X_train and y_train ready\n",
        "\n",
        "# Step 1: Define your SVM model\n",
        "svm_model = SVC(kernel='rbf', gamma='scale', probability=True)  # Example SVM with radial basis function kernel\n",
        "\n",
        "# Step 2: Train your SVM model\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 3: Initialize a SklearnClassifier\n",
        "art_classifier = SklearnClassifier(model=svm_model, clip_values=(0, 1))\n",
        "\n",
        "# Step 4: Convert X_test to a NumPy array\n",
        "X_test_np = X_test.to_numpy()\n",
        "\n",
        "# Step 5: Generate adversarial examples using FGSM\n",
        "attack = FastGradientMethod(estimator=art_classifier, eps=0.2)\n",
        "X_test_adv = attack.generate(X_test_np)\n",
        "\n",
        "# Step 6: Save the adversarial examples in a CSV file\n",
        "adversarial_df = pd.DataFrame(X_test_adv, columns=[f'feature_{i}' for i in range(X_test_adv.shape[1])])\n",
        "adversarial_df.to_csv('adversarial_examples_svmfgsm.csv', index=False)\n",
        "\n",
        "# Step 7: Evaluate the adversarial examples\n",
        "y_pred_adv = svm_model.predict(X_test_adv)\n",
        "report_adv = classification_report(y_test, y_pred_adv)\n",
        "test_accuracy_adv = accuracy_score(y_test, y_pred_adv)\n",
        "precision_adv = precision_score(y_test, y_pred_adv, average='weighted')\n",
        "recall_adv = recall_score(y_test, y_pred_adv, average='weighted')\n",
        "f1_adv = f1_score(y_test, y_pred_adv, average='weighted')\n",
        "\n",
        "# Calculate detection rate\n",
        "detection_rate_adv = (1 - test_accuracy_adv) * 100\n",
        "\n",
        "print(\"Adversarial Precision (SVM):\", precision_adv)\n",
        "print(\"Adversarial Recall (SVM):\", recall_adv)\n",
        "print(\"Adversarial F1 Score (SVM):\", f1_adv)\n",
        "print(\"Adversarial Detection Rate (SVM):\", detection_rate_adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "op8BGthuJ2Pw",
        "outputId": "cc2f86be-4e85-4c7a-9159-6913fa5666f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1227/1227 [==============================] - 4s 3ms/step - loss: 0.2410 - accuracy: 0.9236 - val_loss: 0.1161 - val_accuracy: 0.9608\n",
            "384/384 [==============================] - 1s 1ms/step\n",
            "Adversarial Precision (SVM): 0.757271275683008\n",
            "Adversarial Recall (SVM): 0.7586403651776981\n",
            "Adversarial F1 Score (SVM): 0.7579103195725851\n",
            "Adversarial Detection Rate (SVM): 24.135963482230196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from art.estimators.classification import SklearnClassifier\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have trained the SVM model and have X_train and y_train ready\n",
        "\n",
        "# Step 1: Define your SVM model\n",
        "svm_model = SVC(kernel='rbf', gamma='scale', probability=True)  # Example SVM with radial basis function kernel\n",
        "\n",
        "# Step 2: Train your SVM model\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 3: Initialize a SklearnClassifier\n",
        "art_classifier = SklearnClassifier(model=svm_model, clip_values=(0, 1))\n",
        "\n",
        "# Step 4: Convert X_test to a NumPy array\n",
        "X_test_np = X_test.to_numpy()\n",
        "\n",
        "# Step 5: Generate adversarial examples using FGSM\n",
        "attack = FastGradientMethod(estimator=art_classifier, eps=0.2)\n",
        "X_test_adv = attack.generate(X_test_np)\n",
        "\n",
        "# Step 6: Save the adversarial examples in a CSV file\n",
        "adversarial_df = pd.DataFrame(X_test_adv, columns=[f'feature_{i}' for i in range(X_test_adv.shape[1])])\n",
        "adversarial_df.to_csv('adversarial_examples_svmfgsm.csv', index=False)\n",
        "\n",
        "# Step 7: Evaluate the adversarial examples\n",
        "y_pred_adv = svm_model.decision_function(X_test_adv)  # Using decision function for SVM\n",
        "auc_score_adv = roc_auc_score(y_test, y_pred_adv)\n",
        "\n",
        "print(\"Adversarial AUC Score (SVM):\", auc_score_adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osnkOKfhanX1",
        "outputId": "720eb763-a639-4bcb-cf40-0aaf4b1ab1bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1227/1227 [==============================] - 5s 3ms/step - loss: 0.2057 - accuracy: 0.9313 - val_loss: 0.1044 - val_accuracy: 0.9598\n",
            "384/384 [==============================] - 1s 3ms/step\n",
            "Adversarial AUC Score (SVM): 0.7483838929921048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DNN"
      ],
      "metadata": {
        "id": "eibNJTzzLpvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from art.estimators.classification import TensorFlowV2Classifier\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have trained the DNN model and have X_test_np and y_test ready\n",
        "num_classes = 10  # Assuming num_classes is defined\n",
        "input_shape = X_train.shape[1]  # Assuming X_train is defined\n",
        "\n",
        "# Step 1: Define your DNN model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(input_shape,)),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Step 2: Train your DNN model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Step 3: Generate adversarial examples using FGSM\n",
        "art_classifier = TensorFlowV2Classifier(model=model, nb_classes=num_classes, input_shape=input_shape, clip_values=(0, 1), loss_object=tf.keras.losses.SparseCategoricalCrossentropy())\n",
        "attack = FastGradientMethod(estimator=art_classifier, eps=0.2)\n",
        "X_test_adv = attack.generate(X_test_np)\n",
        "\n",
        "# Step 4: Save the adversarial examples in a CSV file\n",
        "adversarial_df = pd.DataFrame(X_test_adv, columns=[f'feature_{i}' for i in range(X_test_adv.shape[1])])\n",
        "adversarial_df.to_csv('adversarial_examples_fgsmdnn.csv', index=False)\n",
        "\n",
        "# Step 5: Evaluate the adversarial examples\n",
        "y_pred_adv = np.argmax(model.predict(X_test_adv), axis=1)\n",
        "report_adv = classification_report(y_test, y_pred_adv)\n",
        "test_accuracy_adv = accuracy_score(y_test, y_pred_adv)\n",
        "print(\"Adversarial Test Accuracy (DNN):\", test_accuracy_adv)\n",
        "print(\"Adversarial Classification Report (DNN):\")\n",
        "print(report_adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_7NCDudJ2Mj",
        "outputId": "bae5bd58-7f99-43a9-c559-3ab5fa2150b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1227/1227 [==============================] - 4s 2ms/step - loss: 0.2656 - accuracy: 0.9162 - val_loss: 0.1167 - val_accuracy: 0.9551\n",
            "Epoch 2/10\n",
            "1227/1227 [==============================] - 3s 2ms/step - loss: 0.1155 - accuracy: 0.9640 - val_loss: 0.1529 - val_accuracy: 0.9679\n",
            "Epoch 3/10\n",
            "1227/1227 [==============================] - 3s 2ms/step - loss: 0.1097 - accuracy: 0.9711 - val_loss: 0.0753 - val_accuracy: 0.9787\n",
            "Epoch 4/10\n",
            "1227/1227 [==============================] - 4s 3ms/step - loss: 0.0851 - accuracy: 0.9740 - val_loss: 0.0956 - val_accuracy: 0.9759\n",
            "Epoch 5/10\n",
            "1227/1227 [==============================] - 3s 2ms/step - loss: 0.0786 - accuracy: 0.9765 - val_loss: 0.0803 - val_accuracy: 0.9798\n",
            "Epoch 6/10\n",
            "1227/1227 [==============================] - 3s 2ms/step - loss: 0.0709 - accuracy: 0.9778 - val_loss: 0.0630 - val_accuracy: 0.9797\n",
            "Epoch 7/10\n",
            "1227/1227 [==============================] - 3s 2ms/step - loss: 0.0644 - accuracy: 0.9796 - val_loss: 0.0611 - val_accuracy: 0.9796\n",
            "Epoch 8/10\n",
            "1227/1227 [==============================] - 3s 3ms/step - loss: 0.0659 - accuracy: 0.9796 - val_loss: 0.0502 - val_accuracy: 0.9836\n",
            "Epoch 9/10\n",
            "1227/1227 [==============================] - 3s 3ms/step - loss: 0.0567 - accuracy: 0.9814 - val_loss: 0.0545 - val_accuracy: 0.9841\n",
            "Epoch 10/10\n",
            "1227/1227 [==============================] - 3s 2ms/step - loss: 0.0554 - accuracy: 0.9820 - val_loss: 0.0469 - val_accuracy: 0.9834\n",
            "384/384 [==============================] - 1s 1ms/step\n",
            "Adversarial Test Accuracy (DNN): 0.6459895663514835\n",
            "Adversarial Classification Report (DNN):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.65      0.55      4033\n",
            "           1       0.79      0.65      0.71      8235\n",
            "\n",
            "    accuracy                           0.65     12268\n",
            "   macro avg       0.63      0.65      0.63     12268\n",
            "weighted avg       0.68      0.65      0.66     12268\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Calculate precision, recall, and F1 score for adversarial examples\n",
        "precision_adv = precision_score(y_test, y_pred_adv, average='weighted')\n",
        "recall_adv = recall_score(y_test, y_pred_adv, average='weighted')\n",
        "f1_adv = f1_score(y_test, y_pred_adv, average='weighted')\n",
        "\n",
        "# Calculate precision, recall, and F1 score for non-adversarial examples\n",
        "precision_non_adv = precision_score(y_test, y_pred_non_adv, average='weighted')\n",
        "recall_non_adv = recall_score(y_test, y_pred_non_adv, average='weighted')\n",
        "f1_non_adv = f1_score(y_test, y_pred_non_adv, average='weighted')\n",
        "\n",
        "# Calculate detection rate for both adversarial and non-adversarial examples\n",
        "detection_rate_adv = 1 - test_accuracy_adv\n",
        "\n",
        "print(\"Adversarial Precision (DNN):\", precision_adv)\n",
        "print(\"Adversarial Recall (DNN):\", recall_adv)\n",
        "print(\"Adversarial F1 Score (DNN):\", f1_adv)\n",
        "print(\"Detection Rate for Adversarial Examples (DNN):\", detection_rate_adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHqna3mKJ2JS",
        "outputId": "4762ff87-6ca6-4fa7-d214-5a9be45aee4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial Precision (DNN): 0.535011878624934\n",
            "Adversarial Recall (DNN): 0.46380828170850996\n",
            "Adversarial F1 Score (DNN): 0.4757323656653002\n",
            "Detection Rate for Adversarial Examples (DNN): 0.53619171829149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Calculate AUC score for adversarial examples\n",
        "auc_score_adv = roc_auc_score(y_test, y_pred_adv)\n",
        "print(\"Adversarial AUC Score (DNN):\", auc_score_adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdFemQ4UdnTY",
        "outputId": "5a9cedb5-9160-4945-a286-60f574f29f61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adversarial AUC Score (DNN): 0.5928594717965437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IDS-Anta"
      ],
      "metadata": {
        "id": "lfB5wi88MjWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import os\n",
        "\n",
        "class MultiArmedBanditAntColonyOptimization:\n",
        "    def __init__(self, n_arms, n_ants):\n",
        "        self.n_arms = n_arms\n",
        "        self.n_ants = n_ants\n",
        "        self.arms = [SVC(probability=True), LogisticRegression(), RandomForestClassifier(), self.create_dnn_model()]\n",
        "        self.pheromone = np.ones(n_arms)\n",
        "        self.epsilon = 0.1\n",
        "\n",
        "    def create_dnn_model(self):\n",
        "        model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def choose_arm(self):\n",
        "        probabilities = self.pheromone / np.sum(self.pheromone)\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return np.random.choice(self.n_arms)\n",
        "        else:\n",
        "            return np.random.choice(self.n_arms, p=probabilities)\n",
        "\n",
        "    def update(self, arm, reward):\n",
        "        self.pheromone[arm] += reward\n",
        "\n",
        "# Fast Gradient Sign Method (FGSM) for generating adversarial samples\n",
        "def generate_adversarial_sample(model, X, y, epsilon=0.1):\n",
        "    with tf.GradientTape() as tape:\n",
        "        tape.watch(X)\n",
        "        prediction = model(X)\n",
        "        loss = tf.keras.losses.binary_crossentropy(y, prediction)\n",
        "    gradient = tape.gradient(loss, X)\n",
        "    signed_grad = tf.sign(gradient)\n",
        "    adversarial_X = X + epsilon * signed_grad\n",
        "    return adversarial_X\n",
        "\n",
        "# Load the extracted features and labels from the CSV file\n",
        "extracted_features_path = r\"E:\\train\\encoded_features_2017_18.csv\"\n",
        "df_extracted_features = pd.read_csv(extracted_features_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X = df_extracted_features.drop(columns=['Label'])\n",
        "y = df_extracted_features['Label']\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Taining we use the 2017&18 Data and testing we take the 2017 adversial data\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Multi-Armed Bandit with Ant Colony Optimization\n",
        "n_arms = 4  # Number of classifiers\n",
        "n_ants = 10  # Number of ants\n",
        "bandit = MultiArmedBanditAntColonyOptimization(n_arms, n_ants)\n",
        "\n",
        "# Train the Multi-Armed Bandit\n",
        "num_iterations = 10\n",
        "for _ in range(num_iterations):\n",
        "    for _ in range(n_ants):\n",
        "        arm = bandit.choose_arm()\n",
        "        classifier = bandit.arms[arm]\n",
        "        if classifier.__class__.__name__ != 'Sequential':\n",
        "            # For non-DNN classifiers\n",
        "            classifier.fit(X_train, y_train)\n",
        "            y_pred = classifier.predict(X_train)\n",
        "            reward = accuracy_score(y_train, y_pred)\n",
        "            bandit.update(arm, reward)\n",
        "        else:\n",
        "            # For DNN classifier using FGSM for adversarial training\n",
        "            adversarial_X_train = generate_adversarial_sample(classifier, X_train, y_train)\n",
        "            classifier.fit(adversarial_X_train, y_train)\n",
        "            _, accuracy = classifier.evaluate(X_train, y_train, verbose=0)\n",
        "            reward = accuracy\n",
        "            bandit.update(arm, reward)\n",
        "\n",
        "# Choose the best classifier\n",
        "best_arm = np.argmax(bandit.pheromone)\n",
        "best_classifier = bandit.arms[best_arm]\n",
        "\n",
        "# Evaluate the best classifier on the test set\n",
        "if best_classifier.__class__.__name__ != 'Sequential':\n",
        "    y_pred = best_classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    classification_rep = classification_report(y_test, y_pred)\n",
        "else:\n",
        "    _, accuracy = best_classifier.evaluate(X_test, y_test, verbose=0)\n",
        "    y_pred = (best_classifier.predict(X_test) > 0.5).astype(\"int32\")\n",
        "    classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print accuracy and classification report for the original test set\n",
        "print(\"Results for original test set:\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep)\n",
        "\n",
        "# Generate and save adversarial examples for the test set using FGSM\n",
        "adversarial_X_test = generate_adversarial_sample(best_classifier, X_test, y_test)\n",
        "adversarial_samples_dir = \"adversarial_samples\"\n",
        "os.makedirs(adversarial_samples_dir, exist_ok=True)\n",
        "np.savetxt(os.path.join(adversarial_samples_dir, \"adversarial_samples.csv\"), adversarial_X_test, delimiter=\",\")\n",
        "\n",
        "# Evaluate the best classifier on the adversarial test set\n",
        "if best_classifier.__class__.__name__ != 'Sequential':\n",
        "    y_pred_adv = best_classifier.predict(adversarial_X_test)\n",
        "    accuracy_adv = accuracy_score(y_test, y_pred_adv)\n",
        "    classification_rep_adv = classification_report(y_test, y_pred_adv)\n",
        "else:\n",
        "    _, accuracy_adv = best_classifier.evaluate(adversarial_X_test, y_test, verbose=0)\n",
        "    y_pred_adv = (best_classifier.predict(adversarial_X_test) > 0.5).astype(\"int32\")\n",
        "    classification_rep_adv = classification_report(y_test, y_pred_adv)\n",
        "\n",
        "# Print accuracy and classification report for the adversarial test set\n",
        "print(\"\\nResults for adversarial test set:\")\n",
        "print(f\"Accuracy: {accuracy_adv}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep_adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygDsF3-KJ2GS",
        "outputId": "85e384ba-f2c4-4fcd-a7c9-78fcc4c97ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1423/1423 [==============================] - 4s 2ms/step - loss: 0.0248 - accuracy: 0.9970\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 0.0027 - accuracy: 0.9994\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 0.0027 - accuracy: 0.9994\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 0.0020 - accuracy: 0.9993\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 0.0016 - accuracy: 0.9995\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 0.0020 - accuracy: 0.9995\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 0.0012 - accuracy: 0.9997\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 7.7576e-04 - accuracy: 0.9998\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 0.0020 - accuracy: 0.9996\n",
            "1423/1423 [==============================] - 4s 2ms/step - loss: 6.3155e-04 - accuracy: 0.9998\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 7.0334e-04 - accuracy: 0.9997\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9998\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 6.0715e-04 - accuracy: 0.9998\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 4.7657e-04 - accuracy: 0.9999\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 0.0017 - accuracy: 0.9998\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 6.5590e-04 - accuracy: 0.9997\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 4.0169e-04 - accuracy: 0.9999\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 3.9310e-04 - accuracy: 0.9998\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 4.3572e-04 - accuracy: 0.9999\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 5.4910e-04 - accuracy: 0.9998\n",
            "1423/1423 [==============================] - 4s 3ms/step - loss: 9.0287e-04 - accuracy: 0.9998\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 2.9465e-04 - accuracy: 0.9999\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 3.6631e-04 - accuracy: 0.9999\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 3.7428e-04 - accuracy: 0.9998\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 2.9898e-04 - accuracy: 0.9999\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 3.2301e-04 - accuracy: 0.9999\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 5.8552e-04 - accuracy: 0.9999\n",
            "1423/1423 [==============================] - 4s 3ms/step - loss: 0.0043 - accuracy: 0.9998\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 1.1709e-04 - accuracy: 1.0000\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 1.9516e-04 - accuracy: 1.0000\n",
            "1423/1423 [==============================] - 4s 3ms/step - loss: 3.6473e-04 - accuracy: 0.9999\n",
            "1423/1423 [==============================] - 4s 3ms/step - loss: 1.6267e-04 - accuracy: 0.9999\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 2.0216e-04 - accuracy: 1.0000\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 3.6210e-04 - accuracy: 0.9998\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 5.8011e-04 - accuracy: 0.9998\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 0.0011 - accuracy: 0.9998\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 2.1408e-04 - accuracy: 0.9999\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 6.2226e-04 - accuracy: 0.9999\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 2.9719e-04 - accuracy: 0.9999\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 4.5936e-05 - accuracy: 1.0000\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 3.5712e-04 - accuracy: 0.9999\n",
            "1423/1423 [==============================] - 3s 2ms/step - loss: 1.6557e-04 - accuracy: 1.0000\n",
            "1423/1423 [==============================] - 4s 3ms/step - loss: 2.6104e-04 - accuracy: 0.9999\n",
            "356/356 [==============================] - 1s 1ms/step\n",
            "Accuracy: 0.9996485114097595\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       282\n",
            "           1       1.00      1.00      1.00     11099\n",
            "\n",
            "    accuracy                           1.00     11381\n",
            "   macro avg       0.99      1.00      1.00     11381\n",
            "weighted avg       1.00      1.00      1.00     11381\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from art.attacks.evasion import FastGradientMethod\n",
        "from art.estimators.classification import SklearnClassifier, TensorFlowClassifier\n",
        "\n",
        "class MultiArmedBanditAntColonyOptimization:\n",
        "    def __init__(self, n_arms, n_ants):\n",
        "        self.n_arms = n_arms\n",
        "        self.n_ants = n_ants\n",
        "        self.arms = [SVC(probability=True), LogisticRegression(), RandomForestClassifier(), self.create_dnn_model()]\n",
        "        self.pheromone = np.ones(n_arms)\n",
        "        self.epsilon = 0.1\n",
        "\n",
        "    def create_dnn_model(self):\n",
        "        model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(128, activation='relu'),\n",
        "            tf.keras.layers.Dense(64, activation='relu'),\n",
        "            tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "    def choose_arm(self):\n",
        "        probabilities = self.pheromone / np.sum(self.pheromone)\n",
        "        if np.random.rand() < self.epsilon:\n",
        "            return np.random.choice(self.n_arms)\n",
        "        else:\n",
        "            return np.random.choice(self.n_arms, p=probabilities)\n",
        "\n",
        "    def update(self, arm, reward):\n",
        "        self.pheromone[arm] += reward\n",
        "\n",
        "# Load the extracted features and labels from the CSV file\n",
        "extracted_features_path = r\"E:\\train\\encoded_features_2017_18.csv\"\n",
        "df_extracted_features = pd.read_csv(extracted_features_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X = df_extracted_features.drop(columns=['Label'])\n",
        "y = df_extracted_features['Label']\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Taining we use the 2017&18 Data and testing we take the 2017 adversial data\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Multi-Armed Bandit with Ant Colony Optimization\n",
        "n_arms = 4  # Number of classifiers\n",
        "n_ants = 10  # Number of ants\n",
        "bandit = MultiArmedBanditAntColonyOptimization(n_arms, n_ants)\n",
        "\n",
        "# Train the Multi-Armed Bandit\n",
        "num_iterations = 10\n",
        "for _ in range(num_iterations):\n",
        "    for _ in range(n_ants):\n",
        "        arm = bandit.choose_arm()\n",
        "        classifier = bandit.arms[arm]\n",
        "        classifier.fit(X_train, y_train)\n",
        "        if classifier.__class__.__name__ != 'Sequential':\n",
        "            y_pred = classifier.predict(X_train)\n",
        "            reward = accuracy_score(y_train, y_pred)\n",
        "        else:\n",
        "            _, accuracy = classifier.evaluate(X_train, y_train, verbose=0)\n",
        "            reward = accuracy\n",
        "        bandit.update(arm, reward)\n",
        "\n",
        "# Choose the best classifier\n",
        "best_arm = np.argmax(bandit.pheromone)\n",
        "best_classifier = bandit.arms[best_arm]\n",
        "\n",
        "# Create ART classifier for the best classifier\n",
        "if best_classifier.__class__.__name__ != 'Sequential':\n",
        "    art_classifier = SklearnClassifier(model=best_classifier)\n",
        "else:\n",
        "    art_classifier = TensorFlowClassifier(model=self.create_dnn_model(), nb_classes=2, input_shape=X_train.shape[1])\n",
        "\n",
        "# Generate adversarial samples using Fast Gradient Method (FGM)\n",
        "fgm_attack = FastGradientMethod(estimator=art_classifier, eps=0.1)\n",
        "X_test_adv = fgm_attack.generate(X_test)\n",
        "\n",
        "# Evaluate the best classifier on the adversarial test set\n",
        "y_pred_adv = best_classifier.predict(X_test_adv)\n",
        "precision_adv, recall_adv, f1_score_adv, _ = precision_recall_fscore_support(y_test, y_pred_adv, average='binary')\n",
        "auc_score_adv = roc_auc_score(y_test, y_pred_adv)\n",
        "\n",
        "# Compute detection rate on adversarial samples (equivalent to recall)\n",
        "detection_rate_adv = recall_adv\n",
        "\n",
        "# Print precision, recall, detection rate, F1 score, and AUC score on adversarial samples\n",
        "print(\"Precision on adversarial samples:\", precision_adv)\n",
        "print(\"Recall on adversarial samples:\", recall_adv)\n",
        "print(\"Detection Rate on adversarial samples:\", detection_rate_adv)\n",
        "print(\"F1 Score on adversarial samples:\", f1_score_adv)\n",
        "print(\"AUC Score on adversarial samples:\", auc_score_adv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0DKWw4XhqmA",
        "outputId": "9ca1d7bd-3cf9-4581-b97a-ac64d2212e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision on adversarial samples: 0.9883333333333333\n",
            "Recall on adversarial samples: 0.9857265484877259\n",
            "Detection Rate on adversarial samples: 0.9418545945625773\n",
            "F1 Score on adversarial samples: 0.9899497487437185\n",
            "AUC Score on adversarial samples: 0.9894085454978075\n"
          ]
        }
      ]
    }
  ]
}